import os
import cv2
import numpy as np
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, CommandHandler, ContextTypes
from uuid import uuid4
import subprocess
import requests
from deepface import DeepFace
import logging
import base64
import re
import asyncio
import edge_tts
from typing import List, Dict
from PIL import Image, ImageDraw, ImageFont, ImageOps


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


TMP_DIR = 'tmp'
if not os.path.exists(TMP_DIR):
    os.makedirs(TMP_DIR)

USERS_FILE = 'users.txt'


OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"


EDGE_TTS_VOICES = {
    "ru": {
        "male": "ru-RU-DmitryNeural",
        "female": "ru-RU-SvetlanaNeural",
        "unknown": "ru-RU-SvetlanaNeural"
    },
    "en": {
        "male": "en-US-ChristopherNeural",
        "female": "en-US-JennyNeural",
        "unknown": "en-US-JennyNeural"
    }
}

def save_user(user_id):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ñ–∞–π–ª"""
    users = load_users()
    users.add(str(user_id))
    with open(USERS_FILE, 'w') as f:
        f.write('\n'.join(users))

def load_users():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    if not os.path.exists(USERS_FILE):
        return set()
    try:
        with open(USERS_FILE, 'r') as f:
            return set(line.strip() for line in f if line.strip())
    except:
        return set()

def get_user_count():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    return len(load_users())


def check_openrouter_connection():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenRouter API"""
    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
        }
        
        test_payload = {
            "model": "qwen/qwen2.5-vl-72b-instruct",
            "messages": [{"role": "user", "content": "Hello"}],
            "max_tokens": 10
        }
        
        response = requests.post(OPENROUTER_API_URL, headers=headers, json=test_payload, timeout=10)
        return response.status_code == 200
            
    except Exception as e:
        print(f"Connection error: {e}")
        return False

def openrouter_ocr(image_path):
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenRouter"""
    try:
        if not check_openrouter_connection():
            return "API_CONNECTION_ERROR"
        
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
        }
        
        payload = {
            "model": "qwen/qwen-vl-plus",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text", 
                            "text": "–ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Ç–æ—á–Ω–æ –∫–∞–∫ –æ–Ω –Ω–∞–ø–∏—Å–∞–Ω. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                        }
                    ]
                }
            ],
            "max_tokens": 2000,
            "temperature": 0.1
        }
        
        response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
            
            if text and text.strip():
                text = text.strip()
              
                text = re.sub(r'^["\']|["\']$', '', text)
                text = re.sub(r'\*\*|\*\*', '', text)
                text = re.sub(r'`', '', text)
                
           
                text = re.sub(r'^(Text|–¢–µ–∫—Å—Ç|Content|–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ|Result|–†–µ–∑—É–ª—å—Ç–∞—Ç):?\s*', '', text, flags=re.IGNORECASE)
                
           
                text = re.sub(r'\s+', ' ', text).strip()
                
                if text and len(text) > 2:
                    print(f"OCR Success: {text[:100]}...")
                    return text[:2000]
        
        return ""
        
    except Exception as e:
        print(f"OCR Error: {e}")
        return "ERROR"

def detect_gender(image_path):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é DeepFace"""
    try:
        analysis = DeepFace.analyze(
            img_path=image_path,
            actions=['gender'],
            enforce_detection=False,
            detector_backend='retinaface',
            silent=True
        )
        
        if isinstance(analysis, list):
            analysis = analysis[0]
            
        gender = analysis.get('gender', {})
        woman_score = gender.get('Woman', 0)
        man_score = gender.get('Man', 0)
        
        if woman_score > man_score:
            return "female"
        elif man_score > woman_score:
            return "male"
        else:
            return "unknown"
            
    except Exception as e:
        print(f"Gender detection error: {e}")
        return "unknown"

def detect_language_simple(text):
    """–ü—Ä–æ—Å—Ç–æ–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —è–∑—ã–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–º–≤–æ–ª–æ–≤"""
    russian_chars = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
    english_chars = len(re.findall(r'[a-zA-Z]', text))
    
    if russian_chars > english_chars:
        return "ru"
    elif english_chars > russian_chars:
        return "en"
    else:
        return "en"

async def text_to_speech_edge_tts_fast(text, output_path, voice_name):
    """–ë—ã—Å—Ç—Ä–∞—è –æ–∑–≤—É—á–∫–∞ —á–µ—Ä–µ–∑ Edge-TTS –±–µ–∑ –∑–∞–¥–µ—Ä–∂–µ–∫"""
    try:
        print(f"Using Edge-TTS voice: {voice_name}")
        
        communicate = edge_tts.Communicate(text, voice_name, rate="+15%")
        
        await communicate.save(output_path)
        
        if os.path.exists(output_path):
 
            temp_output = output_path.replace('.mp3', '_temp.mp3')
            cmd = [
                'ffmpeg', '-i', output_path,
                '-af', 'silenceremove=start_periods=1:start_duration=0.1:start_threshold=-30dB,'
                       'aresample=async=1:first_pts=0',
                '-c:a', 'libmp3lame', '-q:a', '2', '-y', temp_output
            ]
            
            result = subprocess.run(cmd, capture_output=True, timeout=30)
            
            if result.returncode == 0 and os.path.exists(temp_output):
                os.replace(temp_output, output_path)
                print(f"Fast Edge-TTS audio saved: {output_path}")
                return True
        
        return False
        
    except Exception as e:
        print(f"Edge-TTS error: {e}")
        return False

async def text_to_speech_anime(text, output_path, gender="unknown", voice_choice=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–∑–≤—É—á–∫–∏ —Å –≤—ã–±–æ—Ä–æ–º –≥–æ–ª–æ—Å–∞"""
    print(f"Generating voice for text: {text[:50]}...")
    
    
    language = detect_language_simple(text)
    print(f"Text language: {language}")
    
   
    voice_name = None
    if voice_choice:
        
        voice_name = voice_choice
        print(f"Using user-selected voice: {voice_name}")
    else:
      
        voice_dict = EDGE_TTS_VOICES.get(language, EDGE_TTS_VOICES["en"])
        voice_name = voice_dict.get(gender, voice_dict["unknown"])
        print(f"Using auto-selected voice: {voice_name}")
    
  
    return await text_to_speech_edge_tts_fast(text, output_path, voice_name)


def split_text_into_chunks(text, max_chars=200):
    """–£–º–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º"""
    if len(text) <= max_chars:
        return [text]
    
  
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 <= max_chars:
            if current_chunk:
                current_chunk += " " + sentence
            else:
                current_chunk = sentence
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = sentence
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def create_karaoke_frame_pil(text, current_char_index, width=1280, height=720):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–¥—Ä–∞ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è PIL –∏ —à—Ä–∏—Ñ—Ç Arial"""
   
    image = Image.new('RGB', (width, height), (0, 0, 0))
    draw = ImageDraw.Draw(image)
    
    try:
        
        font = ImageFont.truetype("arial.ttf", 40)
    except:
        try:
           
            font = ImageFont.truetype("arial", 40)
        except:
           
            font = ImageFont.load_default()
    
   
    max_width = width - 100
    line_height = 50
    padding = 20
    
    
    words = text.split()
    lines = []
    current_line = []
    
    for word in words:
        test_line = " ".join(current_line + [word])
        bbox = draw.textbbox((0, 0), test_line, font=font)
        text_width = bbox[2] - bbox[0]
        
        if text_width > max_width and current_line:
            lines.append(" ".join(current_line))
            current_line = [word]
        else:
            current_line.append(word)
    
    if current_line:
        lines.append(" ".join(current_line))
    
    
    max_lines = 4
    if len(lines) > max_lines:
        lines = lines[:max_lines]
    
    
    total_height = len(lines) * line_height
    y_start = (height - total_height) // 2
    
    
    char_count = 0
    for i, line in enumerate(lines):
       
        bbox = draw.textbbox((0, 0), line, font=font)
        text_width = bbox[2] - bbox[0]
        x = (width - text_width) // 2
        y = y_start + i * line_height
        
        
        current_x = x
        for char in line:
           
            color = (255, 255, 0) if char_count < current_char_index else (255, 255, 255)
            
           
            draw.text((current_x, y), char, fill=color, font=font)
            
            
            char_bbox = draw.textbbox((0, 0), char, font=font)
            char_width = char_bbox[2] - char_bbox[0]
            current_x += char_width
            char_count += 1
        
        
        char_count += 1
    
    
    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

def get_audio_duration(audio_path):
    """–¢–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ"""
    try:
        result = subprocess.run([
            'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
        ], capture_output=True, text=True, timeout=10)
        duration = float(result.stdout.strip())
        return max(duration, 0.1)
    except:
        return 5.0

def create_karaoke_video_with_audio(text, audio_path, output_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä–∞–æ–∫–µ-–≤–∏–¥–µ–æ —Å —Ç–æ—á–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –∏—Å–ø–æ–ª—å–∑—É—è PIL"""
    try:
        if not os.path.exists(audio_path):
            return False
        
       
        duration = get_audio_duration(audio_path)
        if duration <= 0:
            return False
            
        fps = 30
        total_frames = int(duration * fps) + 10
        
        width, height = 1280, 720
        temp_video = output_path.replace('.mp4', '_temp.mp4')
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_video, fourcc, fps, (width, height))

        if not out.isOpened():
            return False

        total_chars = len(text)
        chars_per_sec = total_chars / duration if duration > 0 else total_chars / 5.0

        for frame_num in range(total_frames):
            current_time = frame_num / fps
            current_char = min(int(current_time * chars_per_sec), total_chars)
            frame = create_karaoke_frame_pil(text, current_char, width, height)
            out.write(frame)

        out.release()

       
        padded_audio = audio_path.replace('.mp3', '_padded.mp3')
        pad_cmd = [
            'ffmpeg', '-i', audio_path, '-af', 'apad=pad_dur=0.5', '-y', padded_audio
        ]
        subprocess.run(pad_cmd, capture_output=True)

        cmd = [
            'ffmpeg', '-y',
            '-i', temp_video,
            '-i', padded_audio,
            '-c:v', 'libx264',
            '-preset', 'fast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-shortest',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, timeout=120)

       
        for f in [temp_video, padded_audio]:
            if os.path.exists(f):
                os.remove(f)

        return result.returncode == 0 and os.path.exists(output_path)

    except Exception as e:
        print(f"Video creation error: {e}")
        return False


def merge_videos(video_paths: List[str], output_path: str) -> bool:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∏–¥–µ–æ –≤ –æ–¥–Ω–æ"""
    try:
        if not video_paths:
            return False
            
        if len(video_paths) == 1:
            import shutil
            shutil.copy2(video_paths[0], output_path)
            return True
            
        list_file = os.path.join(TMP_DIR, f"concat_list_{uuid4().hex}.txt")
        with open(list_file, 'w', encoding='utf-8') as f:
            for video_path in video_paths:
                abs_path = os.path.abspath(video_path).replace('\\', '/')
                f.write(f"file '{abs_path}'\n")
        
        cmd = [
            'ffmpeg', '-f', 'concat', '-safe', '0', '-i', list_file,
            '-c', 'copy', '-y', output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if os.path.exists(list_file):
            os.remove(list_file)
        
        return result.returncode == 0 and os.path.exists(output_path)
            
    except Exception as e:
        print(f"Video merge error: {e}")
        return False


async def handle_single_photo(update: Update, context, image_path: str, gender: str) -> Dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ç–æ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ"""
    result = {'videos': [], 'audios': [], 'text': ''}
    
    
    text = openrouter_ocr(image_path)
    
    if text in ["API_CONNECTION_ERROR", "ERROR"] or not text:
        return result
        
    result['text'] = text
    
   
    language = detect_language_simple(text)
    language_display = "Russian" if language == "ru" else "English"
    
    chunks = split_text_into_chunks(text, 200)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å
    voice_choice = context.user_data.get('voice_choice')

    for i, chunk in enumerate(chunks):
        try:
            audio_path = os.path.join(TMP_DIR, f"{uuid4().hex}_audio_{i}.mp3")
            
            if not await text_to_speech_anime(chunk, audio_path, gender, voice_choice):
                continue

            if not os.path.exists(audio_path) or os.path.getsize(audio_path) == 0:
                continue
                
            result['audios'].append(audio_path)
            
            video_path = os.path.join(TMP_DIR, f"{uuid4().hex}_karaoke_{i}.mp4")
            
            if create_karaoke_video_with_audio(chunk, audio_path, video_path):
                if os.path.exists(video_path) and os.path.getsize(video_path) > 0:
                    result['videos'].append(video_path)

        except Exception as e:
            print(f"Part {i} error: {e}")
            continue
    
    return result


async def handle_photo(update: Update, context):
    try:
        user_id = update.effective_user.id
        save_user(user_id)
        
        if 'processing_photos' not in context.user_data:
            context.user_data['processing_photos'] = []
        
        file = await update.message.photo[-1].get_file()
        image_id = uuid4().hex
        image_path = os.path.join(TMP_DIR, f"{image_id}.jpg")
        await file.download_to_drive(image_path)
        
        context.user_data['processing_photos'].append(image_path)
        
        count = len(context.user_data['processing_photos'])
        status_msg = await update.message.reply_text(f"üì∏ –§–æ—Ç–æ {count}/5 –¥–æ–±–∞–≤–ª–µ–Ω–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /process —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
        context.user_data['last_status_message'] = status_msg.message_id
        
        if count >= 5:
            await process_photos(update, context)
            
    except Exception as e:
        print(f"Error handling photo: {e}")
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ.")


async def process_photos(update: Update, context):
    try:
        if 'processing_photos' not in context.user_data or not context.user_data['processing_photos']:
            await update.message.reply_text("‚ùå –ù–µ—Ç —Ñ–æ—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            return
        

        if 'last_status_message' in context.user_data:
            try:
                await context.bot.delete_message(
                    chat_id=update.effective_chat.id,
                    message_id=context.user_data['last_status_message']
                )
            except:
                pass
        

        processing_msg = await update.message.reply_text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞—á–∞—Ç–∞...")
        
        photos = context.user_data['processing_photos']
        
        all_videos = []
        all_audios = []
        
        for i, photo_path in enumerate(photos):
            try:
                if not os.path.exists(photo_path):
                    continue
                    
                gender = detect_gender(photo_path)
                result = await handle_single_photo(update, context, photo_path, gender)
                
                all_videos.extend([v for v in result['videos'] if os.path.exists(v) and os.path.getsize(v) > 0])
                all_audios.extend([a for a in result['audios'] if os.path.exists(a)])
                
                if os.path.exists(photo_path):
                    os.remove(photo_path)
                    
            except Exception as e:
                print(f"Error processing photo {i+1}: {e}")
                continue
        
        context.user_data['processing_photos'] = []
        

        try:
            await context.bot.delete_message(
                chat_id=update.effective_chat.id,
                message_id=processing_msg.message_id
            )
        except:
            pass
        
        if all_videos:
           
            merging_msg = await update.message.reply_text("üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ...")
            
            merged_video_path = os.path.join(TMP_DIR, f"{uuid4().hex}_merged_karaoke.mp4")
            
            if merge_videos(all_videos, merged_video_path):
                try:
                    if os.path.exists(merged_video_path) and os.path.getsize(merged_video_path) > 1024:
                       
                        try:
                            await context.bot.delete_message(
                                chat_id=update.effective_chat.id,
                                message_id=merging_msg.message_id
                            )
                        except:
                            pass
                        
                        
                        with open(merged_video_path, 'rb') as f:
                            await update.message.reply_video(
                                video=f,
                                caption="‚úÖ –í–∞—à–µ –∫–∞—Ä–∞–æ–∫–µ-–≤–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ!",
                                supports_streaming=True,
                                read_timeout=60,
                                write_timeout=60,
                                connect_timeout=60
                            )
                except Exception as e:
                    print(f"Error sending video: {e}")
                    await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ. –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º.")
                
                if os.path.exists(merged_video_path):
                    os.remove(merged_video_path)
        else:
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –¥—Ä—É–≥–∏–º–∏ —Ñ–æ—Ç–æ.")

        
        for file_path in all_videos + all_audios:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
                
    except Exception as e:
        print(f"Error processing photos: {e}")
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ.")
       
        if 'processing_photos' in context.user_data:
            for photo_path in context.user_data['processing_photos']:
                if os.path.exists(photo_path):
                    os.remove(photo_path)
            context.user_data['processing_photos'] = []

async def clear_photos(update: Update, context):
    """–û—á–∏—Å—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ —Ñ–æ—Ç–æ"""
    if 'processing_photos' in context.user_data:
        
        for photo_path in context.user_data['processing_photos']:
            if os.path.exists(photo_path):
                os.remove(photo_path)
        
        count = len(context.user_data['processing_photos'])
        context.user_data['processing_photos'] = []
        await update.message.reply_text(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ {count} —Ñ–æ—Ç–æ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.")
    else:
        await update.message.reply_text("‚ÑπÔ∏è –í –æ—á–µ—Ä–µ–¥–∏ –Ω–µ—Ç —Ñ–æ—Ç–æ.")


async def show_queue(update: Update, context):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –æ—á–µ—Ä–µ–¥—å —Ñ–æ—Ç–æ"""
    if 'processing_photos' in context.user_data and context.user_data['processing_photos']:
        count = len(context.user_data['processing_photos'])
        await update.message.reply_text(f"üìä –í –æ—á–µ—Ä–µ–¥–∏ {count} —Ñ–æ—Ç–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /process —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
    else:
        await update.message.reply_text("‚ÑπÔ∏è –í –æ—á–µ—Ä–µ–¥–∏ –Ω–µ—Ç —Ñ–æ—Ç–æ.")


async def show_voices(update: Update, context):
    """–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞"""
    current_voice = context.user_data.get('voice_choice', '–ê–≤—Ç–æ –≤—ã–±–æ—Ä')
    voices_text = (
        "üéôÔ∏è –î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞:\n\n"
        "–†—É—Å—Å–∫–∏–µ –≥–æ–ª–æ—Å–∞:\n"
        "/voice_ru_male - –î–º–∏—Ç—Ä–∏–π (–º—É–∂—Å–∫–æ–π)\n"
        "/voice_ru_female - –°–≤–µ—Ç–ª–∞–Ω–∞ (–∂–µ–Ω—Å–∫–∏–π)\n\n"
        "–ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –≥–æ–ª–æ—Å–∞:\n"
        "/voice_en_male - –ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä (–º—É–∂—Å–∫–æ–π)\n"
        "/voice_en_female - –î–∂–µ–Ω–Ω–∏ (–∂–µ–Ω—Å–∫–∏–π)\n\n"
        "–ê–≤—Ç–æ –≤—ã–±–æ—Ä:\n"
        "/voice_auto - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä\n\n"
        f"üîä –¢–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å: {current_voice}"
    )
    await update.message.reply_text(voices_text)

async def set_voice_ru_male(update: Update, context):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –º—É–∂—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
    context.user_data['voice_choice'] = "ru-RU-DmitryNeural"
    await update.message.reply_text("üá∑üá∫ –í—ã–±—Ä–∞–Ω —Ä—É—Å—Å–∫–∏–π –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å: –î–º–∏—Ç—Ä–∏–π")

async def set_voice_ru_female(update: Update, context):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∂–µ–Ω—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
    context.user_data['voice_choice'] = "ru-RU-SvetlanaNeural"
    await update.message.reply_text("üá∑üá∫ –í—ã–±—Ä–∞–Ω —Ä—É—Å—Å–∫–∏–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å: –°–≤–µ—Ç–ª–∞–Ω–∞")

async def set_voice_en_male(update: Update, context):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –º—É–∂—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
    context.user_data['voice_choice'] = "en-US-ChristopherNeural"
    await update.message.reply_text("üá∫üá∏ –í—ã–±—Ä–∞–Ω –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å: –ö—Ä–∏—Å—Ç–æ—Ñ–µ—Ä")

async def set_voice_en_female(update: Update, context):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∂–µ–Ω—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
    context.user_data['voice_choice'] = "en-US-JennyNeural"
    await update.message.reply_text("üá∫üá∏ –í—ã–±—Ä–∞–Ω –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∂–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å: –î–∂–µ–Ω–Ω–∏")

async def set_voice_auto(update: Update, context):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –≥–æ–ª–æ—Å–∞"""
    if 'voice_choice' in context.user_data:
        del context.user_data['voice_choice']
    await update.message.reply_text("üîä –í–∫–ª—é—á–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –≥–æ–ª–æ—Å–∞")


async def start(update: Update, context):
    user_id = update.effective_user.id
    save_user(user_id)

    welcome_text = (
        "üé¨ –ê–Ω–∏–º–µ-–±–æ—Ç-–æ–∑–≤—É—á–∫–∞\n\n"
        "–ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ –º–Ω–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å —Ç–µ–∫—Å—Ç–æ–º ‚Üí —è —Å–æ–∑–¥–∞–º –∫–∞—Ä–∞–æ–∫–µ-–≤–∏–¥–µ–æ! üé§\n\n"
        "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n"
        "1. –í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å (/voices) - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n"
        "2. –ü—Ä–∏—Å—ã–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å —Ç–µ–∫—Å—Ç–æ–º\n"
        "3. –í–≤–µ–¥–∏—Ç–µ /process —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É\n"
        "4. –ü–æ–ª—É—á–∏—Ç–µ —Å–≤–æ–µ –≤–∏–¥–µ–æ!\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/voices - –≤—ã–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å\n"
        "/process - –Ω–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É\n"
        "/clear - –æ—á–∏—Å—Ç–∏—Ç—å –æ—á–µ—Ä–µ–¥—å\n"
        "/queue - –ø–æ–∫–∞–∑–∞—Ç—å –æ—á–µ—Ä–µ–¥—å\n\n"
        "üì∏ –ú–∞–∫—Å–∏–º—É–º 5 —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ"
        "–°–æ–≤–µ—Ç—É–µ–º –∑–∞–∫–∏–Ω—É—Ç—å –¥–æ–Ω–∞—Ç, —á—Ç–æ–±—ã —Å–µ—Ä–≤–∏—Å —Ä–∞–±–æ—Ç–∞–ª —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ!"
    )
    await update.message.reply_text(welcome_text)

def main():
    TOKEN = ""
    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("process", process_photos))
    app.add_handler(CommandHandler("clear", clear_photos))
    app.add_handler(CommandHandler("queue", show_queue))
    app.add_handler(CommandHandler("voices", show_voices))
    app.add_handler(CommandHandler("voice_ru_male", set_voice_ru_male))
    app.add_handler(CommandHandler("voice_ru_female", set_voice_ru_female))
    app.add_handler(CommandHandler("voice_en_male", set_voice_en_male))
    app.add_handler(CommandHandler("voice_en_female", set_voice_en_female))
    app.add_handler(CommandHandler("voice_auto", set_voice_auto))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    print(" Bot running.")
    app.run_polling()

if __name__ == '__main__':
    main()
    # @VFaiengineer


